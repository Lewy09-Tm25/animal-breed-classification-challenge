{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh8lQDYvtnoW",
        "outputId": "7807926b-0f6a-489b-a983-11c7a683680a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4Ny6FMYt1Ap"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "image_gen = ImageDataGenerator(rotation_range=20, # rotate the image 20 degrees\n",
        "                               width_shift_range=0.10, # Shift the pic width by a max of 5%\n",
        "                               height_shift_range=0.10, # Shift the pic height by a max of 5%\n",
        "                               #rescale=1/255, # Rescale the image by normalzing it.\n",
        "                               # note: not using rescale because we're using preprocessing function\n",
        "                               shear_range=0.1, # Shear means cutting away part of the image (max 10%)\n",
        "                               zoom_range=0.1, # Zoom in by 10% max\n",
        "                               horizontal_flip=True, # Allo horizontal flipping\n",
        "                               fill_mode='nearest', # Fill in missing pixels with the nearest filled value\n",
        "                               #validation_split=0.1, # adding validation split\n",
        "                               preprocessing_function=tf.keras.applications.inception_v3.preprocess_input\n",
        "                               # note that inception_v3 requires the above preprocessing function to be used\n",
        "                               # to set values between -1 & +1\n",
        "                              )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn2_usFyuF5a",
        "outputId": "1de8ae7e-141a-4f79-c1da-0535d87b98c5"
      },
      "source": [
        "train_gen=image_gen.flow_from_directory('drive/My Drive/TRAIN')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5890 images belonging to 37 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P7YWfKWulJR",
        "outputId": "1248e3c0-dc34-4d0b-caea-9794ebef3779"
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "\n",
        "base_model = InceptionV3(\n",
        "    weights='imagenet', include_top=False, \n",
        "    input_shape=(400,400,3) #pooling='avg'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4c7TjDEu38I"
      },
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "# ensuring we don't train the base model\n",
        "base_model.trainable = False\n",
        "x = base_model.output\n",
        "# passing Inception output via pooling layer\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "#x = tf.keras.layers.Dropout(0.2)(x)  # preventing overfitting with dropout\n",
        "# Flattening the inputs to custom layers\n",
        "#x = Flatten()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "#x = Dense(50, activation='relu')(x)\n",
        "# and a logistic layer \n",
        "predictions = Dense(37, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKA5KI2pvFcr"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=[tf.keras.metrics.Precision()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jN2di5BJvKru"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFRWc9s6vTau"
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss',patience=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYCZnPkWvWV-",
        "outputId": "77bdcea0-217b-42bc-c966-5458a67c433c"
      },
      "source": [
        "train_image_gen = image_gen.flow_from_directory('drive/My Drive/TRAIN',\n",
        "                                               target_size=(400,400),\n",
        "                                                color_mode='rgb',\n",
        "                                               batch_size=16,\n",
        "                                               class_mode='categorical', \n",
        "                                                #subset='training'\n",
        "                                               )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5890 images belonging to 37 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA2IMP_fwNc1"
      },
      "source": [
        "# # validation images\n",
        "# test_image_gen = image_gen.flow_from_directory(train_path,\n",
        "#                                                target_size=image_shape[:2],\n",
        "#                                                 color_mode='rgb',\n",
        "#                                                batch_size=batch_size,\n",
        "#                                                class_mode='categorical',\n",
        "#                                                subset='validation')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U69AK-F5wDi2",
        "outputId": "1f4c0b68-6bf2-40c2-f696-f56fe16a6908"
      },
      "source": [
        "model.fit(\n",
        "    x=train_image_gen,\n",
        "    epochs=7,\n",
        "#    callbacks=[early_stop],\n",
        "#    validation_data=test_image_gen\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "369/369 [==============================] - 1662s 4s/step - loss: 0.6169 - precision: 0.9003\n",
            "Epoch 2/7\n",
            "369/369 [==============================] - 199s 539ms/step - loss: 0.2708 - precision: 0.9264\n",
            "Epoch 3/7\n",
            "369/369 [==============================] - 199s 540ms/step - loss: 0.2267 - precision: 0.9339\n",
            "Epoch 4/7\n",
            "369/369 [==============================] - 196s 532ms/step - loss: 0.1903 - precision: 0.9448\n",
            "Epoch 5/7\n",
            "369/369 [==============================] - 197s 532ms/step - loss: 0.1591 - precision: 0.9485\n",
            "Epoch 6/7\n",
            "369/369 [==============================] - 196s 532ms/step - loss: 0.1648 - precision: 0.9515\n",
            "Epoch 7/7\n",
            "369/369 [==============================] - 196s 531ms/step - loss: 0.1519 - precision: 0.9506\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f21600619d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRS6GwArBH54"
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "fname,test=[],[]\n",
        "\n",
        "test_dir='drive/My Drive/TEST'\n",
        "\n",
        "for infile in glob.glob(test_dir+\"/*.jpg\"):\n",
        "  img=Image.open(infile)\n",
        "  img=img.resize((400,400))\n",
        "  fname.append(infile.split('/')[-1])\n",
        "  img_arr=np.asarray(img)\n",
        "  test.append(img_arr.reshape(400,400,3))\n",
        "\n",
        "test_len=len(test)\n",
        "test=np.array(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybOoOD9eBbY3"
      },
      "source": [
        "maps = {v: k for k, v in train_image_gen.class_indices.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q88Sigl-Bd_G"
      },
      "source": [
        "dense = 0\n",
        "if dense == 1:\n",
        "    test = test.reshape(test_len, 3072)\n",
        "    \n",
        "#test = test / 255.\n",
        "    \n",
        "y_test_pred = np.argmax(model.predict(test), axis=1).tolist()\n",
        "y_test_pred = [maps[val] for val in y_test_pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtivDZ7fBfrC"
      },
      "source": [
        "result=pd.DataFrame({'Filename':fname, 'Class':y_test_pred})\n",
        "result.to_csv('res.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}